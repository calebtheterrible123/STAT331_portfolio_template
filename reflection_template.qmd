---
title: "STAT 331 Portfolio"
author: "Caleb Terrell"
format: html 
embed-resources: true
layout: margin-left
editor: visual
execute: 
  eval: false
  echo: true
---

[**My Grade:**]{.underline} I believe my grade equivalent to course work evidenced below to be an C.

[**Learning Objective Evidence:**]{.underline} In the code chunks below, provide code from Lab or Challenge assignments where you believe you have demonstrated proficiency with the specified learning target. Be sure to specify **where** the code came from (e.g., Lab 4 Question 2).

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv` Example 1

```{r}
#| label: CSV Example 1 
# Lab 3 Question 2 
data <- read_csv(here("teacher_evals.csv")) 

```

-   `csv` Example 2

```{r}
#| label: XLSX
# Check In 2.3 
agesxl <- read_xlsx(path = here::here("Week 2", "Check-ins", "Ages_Data", "ages.xlsx"), sheet = "ages"
)
```

-   `xlsx`

```{r}
#| label:  CSV Example 2 
# Challenge 3
childcare_costs <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-05-09/childcare_costs.csv')
counties <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-05-09/counties.csv')
tax_rev <- read_csv('https://atheobold.github.io/groupworthy-data-science/labs/instructions/data/ca_tax_revenue.csv') 


```

**WD-2: I can select necessary columns from a data set.**

-   Example selecting specified columns

```{r}
#| label: wd-2-ex-1
# Lab 3 Q 5 
# This code shows that I can choose the necessary columns from the dataset by only keeping the variables that matter to my analysis using select() after cleaning and formatting the data.
 teacher_evals_clean <- data %>%
  rename(sex = gender) %>% 
  
  filter(no_participants >= 10) %>%
  
  mutate(
    teacher_id = as.character(teacher_id), 
    course_id  = as.character(course_id),
    sex = as.factor(sex),
    academic_degree = as.factor(academic_degree),
    seniority = as.integer(seniority)
  ) %>%
  
  select(course_id, teacher_id, question_no, no_participants, resp_share,
         SET_score_avg, percent_failed_cur, academic_degree, seniority, sex)

glimpse(teacher_evals_clean)

```

-   Example removing specified columns

```{r}
#| label: wd-2-ex-2

```

-   Example selecting columns based on logical values (e.g., `starts_with()`, `ends_with()`, `contains()`, `where()`)

```{r}
#| label: wd-2-ex-3
# Lab 4 Q7
#I used starts_with("mfcc_") inside pivot_longer(), and this selected all childcare cost  columns starting with the same prefix, instead of listing each column manually.
childcare_long <- ca_childcare |>
  select(region, study_year, mfcc_infant, mfcc_toddler, mfcc_preschool) |>
  pivot_longer(
    cols = starts_with("mfcc_"),
    names_to = "care_type",
    values_to = "median_price"
  )

```

**WD-3: I can filter rows from a data frame for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   Numeric Example 1

```{r}
#| label: wd-3-numeric-ex-1
# Lab 3 Q 5 
# this code filters rows based on keeping courses with at minimum 10 participants.
filter(no_participants >= 10)

```

-   Numeric Example 2

```{r}
#| label: wd-3-numeric-ex-1
# Lab 3 Q 5 
filter(study_year %in% c(2008, 2018))

```

-   Character Example 1 (any context)

```{r}
#| label: wd-3-character
# Lab 4, Question 2
# this filters based on a column of characters (state_abbreviation) to keep only the rows where the value equals "CA", showing I can filter character data 
ca_childcare <- counties |>
  filter(state_abbreviation == "CA") |>  
  inner_join(childcare_costs, by = "county_fips_code")

```

-   Character Example 2 (example must use functions from **stringr**)

```{r}
#| label: wd-3-string
# Lab 5 
witnesses <- person |>
  filter(
    str_detect(address_street_name, "Northwestern") |
    str_detect(address_street_name, "Franklin") |
    str_detect(name, "Ann")
  )

```

-   Date (example must use functions from **lubridate**)

```{r}
#| label: wd-3-date
# Lab 5 (edited)
# I edited my lab 5 to use a function from lubridate, as before I was confused and researched a different way to do it- numeric filtering, which I included links to the documentation that I used in my lab on my lab report. This time I went through the slides on canvas to understand lubridate better and apply it to my code, editing this part of my code. I would have to include library(lubridate) in my YAML to make this code run in my lab 
crime_scene_report |> 
  mutate(date = ymd(date)) |> 
  filter(date == ymd("2018-01-15")
```

**WD-4: I can modify existing variables and create new variables in a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   Numeric Example 1

```{r}
#| label: wd-4-numeric-ex-1
# Lab 4 Q 5 
# This creates a new variable from the median of mhi_2018
summarize(
  median_income = median(mhi_2018, na.rm = TRUE),
  .groups = "drop"
)
```

-   Numeric Example 2

```{r}
#| label: wd-4-numeric-ex-2
# Lab 3 Q 5
mutate(
  seniority = as.integer(seniority)
)
```

-   Factor Example 1 (renaming levels)

```{r}
#| label: wd-4-factor-ex-1
# Lab 3 Q 5 
rename(sex = gender) %>%
mutate(sex = as.factor(sex))
```

-   Factor Example 2 (reordering levels)

```{r}
#| label: wd-4-factor-ex-2
# Lab 4 Q 4
region = fct_relevel(region,
  "Superior California",
  "North Coast",
  "San Francisco, Bay Area",
  "Northern San Joaquin Valley",
  "Central Coast",
  "Southern San Joaquin Valley",
  "Inland Empire",
  "Los Angeles",
  "Orange County",
  "San Diego Imperial"
)
```

-   Character (example must use functions from **stringr**)

```{r}
#| label: wd-4-string
# Lab 4 Q4
mutate(
  county_name = str_remove(county_name, " County")
)
```

-   Date (example must use functions from **lubridate**)

```{r}
#| label: wd-4-date
# lab 5 
crime_scene_report |>
  mutate(date = ymd(date)) |>
  filter(date == ymd("2018-01-15"))

```

**WD-5: I can use mutating joins to combine multiple dataframes.**

-   `left_join()` Example 1

```{r}
#| label: wd-5-left-ex-1
# lab 4 q 3
ca_childcare <- tax_rev |>    
  left_join(x = ca_childcare, 
            y = tax_rev, 
            by = join_by(county_name == entity_name, study_year == year))

```

-   `right_join()` Example 1

```{r}
#| label: wd-5-right


```

-   `left_join()` **or** `right_join()` Example 2

```{r}
#| label: wd-5-left-right-ex-2

```

-   `inner_join()` Example 1

```{r}
#| label: wd-5-inner-ex-1
# Lab 5
gym_people <- get_fit_now_member |>
  inner_join(person, by = c("person_id" = "id"))
```

-   `inner_join()` Example 2

```{r}
#| label: wd-5-inner-ex-2
# Lab 5 
final_suspects <- people_cars_suspects |>
  inner_join(gym_suspects, by = c("id" = "person_id"))
```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`

```{r}
#| label: wd-6-semi


```

-   `anti_join()`

```{r}
#| label: wd-6-anti

```

**WD-7: I can pivot dataframes from long to wide and visa versa**

-   `pivot_longer()`

```{r}
#| label: wd-7-long

```

-   `pivot_wider()`

```{r}
#| label: wd-7-wide
# lab 4 q 5 
region_income_summary <- ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(region, study_year) |>
  summarize(
    median_income = median(mhi_2018, na.rm = TRUE),
    .groups = "drop"
  ) |>
  pivot_wider(
    names_from = study_year,
    values_from = median_income,
    names_glue = "median_income_{study_year}"
  )

```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

The following assignments satisfy the above criteria:

-   Lab 4 after revisions
-   Challenge 1
-   Lab 5
-   
-   

**R-2: I can write well documented and tidy code.**

-   Example of **ggplot2** plotting

```{r}
#| label: r-2-1
# Lab 1 q 6
ggplot(data = ToothGrowth,
       mapping = aes(x = supp, y = len)) +
  geom_boxplot() +
  labs(x = "Supplement", y = "Length of Teeth (mm)")

```

-   Example of **dplyr** pipeline

```{r}
#| label: r-2-2
# Lab 3 q 5
teacher_evals_clean <- data %>%
  rename(sex = gender) %>%
  filter(no_participants >= 10) %>%
  mutate(
    teacher_id = as.character(teacher_id),
    course_id  = as.character(course_id),
    sex = as.factor(sex)
  ) %>%
  select(course_id, teacher_id, question_no, no_participants, resp_share,
         SET_score_avg, percent_failed_cur, academic_degree, seniority, sex)
```

-   Example of function formatting

```{r}
#| label: r-2-3

```

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example (any context)

```{r}
#| label: r-3-example
# Lab 4 q 5
#  code is robust because na.rm = TRUE prevents the code from breaking if NA data values are brought in mhi_2018 
region_income_summary <- ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(region, study_year) |>
  summarize(
    median_income = median(mhi_2018, na.rm = TRUE),
    .groups = "drop"
  )
```

-   Example (function stops)

```{r}
#| label: r-3-function-stops
# Lab 3 q 5 
# prevents invalid data from  being used by filterng out unreliable/bad inputs, stopping the function
teacher_evals_clean <- data %>%
  rename(sex = gender) %>% 
  filter(no_participants >= 10) %>%
  mutate(
    teacher_id = as.character(teacher_id), 
    course_id  = as.character(course_id),
    sex = as.factor(sex),
    academic_degree = as.factor(academic_degree),
    seniority = as.integer(seniority)
  ) %>%
  select(course_id, teacher_id, question_no, no_participants, resp_share,
         SET_score_avg, percent_failed_cur, academic_degree, seniority, sex) 
```

## Data Visualization & Summarization

**DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   At least two numeric variables

```{r}
#| label: dvs-1-num
# lab 2 q 4 
ggplot(data = surveys,
       mapping = aes(x = weight, y = hindfoot_length)) +
  geom_point(alpha = 0.25) 
```

-   At least one numeric variable and one categorical variable

```{r}
#| label: dvs-2-num-cat
# Lab 2 q10
ggplot(data = surveys,
       mapping = aes(x = species, y = weight)) +
  geom_jitter(width = 0.3, color = "blue", alpha = 0.25) +
  geom_boxplot(outlier.shape = NA)
```

-   At least two categorical variables

```{r}
#| label: dvs-2-cat

```

-   Dates (time series plot)

```{r}
#| label: dvs-2-date

```

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   I can modify my plot theme to be more readable

```{r}
#| label: dvs-2-ex-1
# Lab 2 q 15 
ggplot(data = surveys,
       mapping = aes(x = species, y = weight)) +
  geom_jitter(width = 0.3, color = "blue", alpha = 0.25) +
  geom_boxplot(outlier.shape = NA) +
  theme(axis.text.x = element_text(angle = 45))

```

-   I can modify my colors to be accessible to anyone's eyes

```{r}
#| label: dvs-2-ex-2
# Lab 2 q 13 
geom_jitter(width = 0.3, color = "blue", alpha = 0.25)

```

-   I can modify my plot titles to clearly communicate the data context

```{r}
#| label: dvs-2-ex-3
# lab 2 q 7 d
ggplot(data = surveys,
       mapping = aes(x = weight, y = hindfoot_length)) +
  geom_point(alpha = 0.25) +
  labs(title = "Animal weight & hindfoot length by species",
       x = "Weight (g)",
       y = "Hindfoot length (mm)")
```

-   I can modify the text in my plot to be more readable

```{r}
#| label: dvs-2-ex-4

```

-   I can reorder my legend to align with the colors in my plot

```{r}
#| label: dvs-2-ex-5


```

**DVS-3: I show creativity in my visualizations**

-   I can use non-standard colors (Example 1)

```{r}
#| label: dvs-3-1-ex-1

```

-   I can use non-standard colors (Example 2)

```{r}
#| label: dvs-3-1-ex-2

```

-   I can use annotations (e.g., `geom_text()`)

```{r}
#| label: dvs-3-2

```

-   I can choose creative geometries (e.g., `geom_segment()`, `geom_ribbon)()`)

```{r}
#| label: dvs-3-3

```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example using `summarize()`

```{r}
#| label: dvs-4-summarize
# Lab 4 q 5 
region_income_summary <- ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(region, study_year) |>
  summarize(
    median_income = median(mhi_2018, na.rm = TRUE),
    .groups = "drop"
  )
```

-   Example using `across()`

```{r}
#| label: dvs-4-across

```

**DVS-5: I can find summaries of variables across multiple groups.**

-   Example 1

```{r}
#| label: dvs-5-1
# lab 4 q 5 
region_income_summary <- ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(region, study_year) |>
  summarize(
    median_income = median(mhi_2018, na.rm = TRUE),
    .groups = "drop"
  )
```

-   Example 2

```{r}
#| label: dvs-5-2

```

**DVS-6: I can create tables which make my summaries clear to the reader.**

-   I can modify my column names to clearly communicate the data context

```{r}
#| label: dvs-6-ex-1
# Lab 4 q 5 
# this is renaming my columns to names that make more sense in context using names_glue, which has a link in my lab (reviewed how I did this with slides and with this link: https://tidyr.tidyverse.org/reference/pivot_wider.html )
region_income_summary <- ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(region, study_year) |>
  summarize(
    median_income = median(mhi_2018, na.rm = TRUE),
    .groups = "drop"
  ) |>
  pivot_wider(
    names_from = study_year,
    values_from = median_income,
    names_glue = "median_income_{study_year}"
  )
```

-   I can modify the text in my table to be more readable (e.g., bold face for column headers)

```{r}
#| label: dvs-6-ex-2

```

-   I can arrange my table to have an intuitive ordering

```{r}
#| label: dvs-6-ex-3
# Lab 4 q 5 
# arranging by descending 
region_income_summary <- ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(region, study_year) |>
  summarize(
    median_income = median(mhi_2018, na.rm = TRUE),
    .groups = "drop"
  ) |>
  pivot_wider(
    names_from = study_year,
    values_from = median_income,
    names_glue = "median_income_{study_year}"
  ) |>
  arrange(desc(median_income_2018))

```

**DVS-7: I show creativity in my tables.**

-   I can use non-default colors

```{r}
#| label: dvs-7-ex-1

```

-   I can modify the layout of my table to be more readable (e.g., `pivot_longer()` or `pivot_wider()`)

```{r}
#| label: dvs-7-ex-2
# lab 4 q 5 
region_income_summary <- ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(region, study_year) |>
  summarize(
    median_income = median(mhi_2018, na.rm = TRUE),
    .groups = "drop"
  ) |>
  pivot_wider(
    names_from = study_year,
    values_from = median_income,
    names_glue = "median_income_{study_year}"
  )

```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call with multiple inputs (rather than multiple function calls)

```{r}
#| label: pe-1-one-call
# lab 2 q 2 
dim(surveys)

```

-   using `across()`

```{r}
#| label: pe-1-across

```

-   using functions from the `map()` family

```{r}
#| label: pe-1-map-1

```

**PE-2: I can write functions to reduce repetition in my code.**

-   Example 1: Function that operates on vectors

```{r}
#| label: pe-2-1

```

-   Example 2: Function that operates on data frames

```{r}
#| label: pe-2-2

```

-   Example 3: Function that operates on vectors *or* data frames

```{r}
#| label: pe-2-3

```

**PE-3:I can use iteration to reduce repetition in my code.**

-   using `across()`

```{r}
#| label: pe-3-across

```

-   using a `map()` function with **one** input (e.g., `map()`, `map_chr()`, `map_dbl()`, etc.)

```{r}
#| label: pe-3-map-1

```

-   using a `map()` function with **more than one** input (e.g., `map_2()` or `pmap()`)

```{r}
#| label: pe-3-map-2

```

**PE-4: I can use modern tools when carrying out my analysis.**

-   I can use functions which are not superseded or deprecated

```{r}
#| label: pe-4-1
# lab 3 q 5 
teacher_evals_clean <- data %>%
  rename(sex = gender) %>% 
  filter(no_participants >= 10) %>%
  mutate(
    teacher_id = as.character(teacher_id), 
    course_id  = as.character(course_id),
    sex = as.factor(sex),
    academic_degree = as.factor(academic_degree),
    seniority = as.integer(seniority)
  ) %>%
  select(course_id, teacher_id, question_no, no_participants, resp_share,
         SET_score_avg, percent_failed_cur, academic_degree, seniority, sex)
```

-   I can connect a data wrangling pipeline into a `ggplot()`

```{r}
#| label: pe-4-2
# lab 1 q 6 / 7 
ToothGrowth %>% 
  mutate(dose = as.factor(dose)) %>% 
  ggplot(mapping = aes(x = dose, y = len)) +
  geom_boxplot() +
  labs(x = "Dose of Supplement (mg/day)", y = "Length of Teeth (mm)")
```

## Data Simulation & Statisical Models

**DSSM-1: I can simulate data from a *variety* of probability models.**

-   Example 1

```{r}
#| label: dsm-1-1

```

-   Example 2

```{r}
#| label: dsm-1-2

```

**DSSM-2: I can conduct common statistical analyses in R.**

-   Example 1

```{r}
#| label: dsm-2-1
# lab 1 q9 
# t - test 
t.test(len ~ supp, 
       data = ToothGrowth, 
       var.equal = FALSE,   
       alternative = "two.sided")
```

-   Example 2

```{r}
#| label: dsm-2-2
# lab 2 q 17
# ANOVA
species_mod <- aov(weight ~ species_id, data = surveys)
summary(species_mod)
```

-   Example 3

```{r}
#| label: dsm-2-3

```

## Revising My Thinking

In the course, I was always revising my final product based on feedback. I redid labs and challenges before turning in to improve the work. At first, I did not always add in code comments or elaborate reflections, but eventually, I built the habit of explaining what and why I had done something so it illustrated my understanding and my growth. I often times did not fully correct my codes mistakes. Lately I have been adding comments to explain how I had changed something and how the new code was clearer, more efficient, or more correct. I have been growing a lot as a student in this course. This was helpful for making better connections between my feedback and future assignments, and allowed me to apply lessons more intentionally.

## Extending My Thinking 

I engaged in extended thinking by doing work that was above and beyond the minimum requirement of assignment and worked to apply new tools and thinking. When faced with a viewing and analyzing challenge, I often took the challenging option even when it was not only more time-consuming, but also took some research. When I could not remember how to code a solution in R, I took it upon myself to look through the documentation, trying out functions in tidyverse, and writing or referencing what I used externally. I made an effort to write things I could understand and modify instead of simply copying someone's work. I also made it important to use only functions that made sense and ideally would be efficient. For instance, I tried to always use mutate() for transforming my data, piping (\|\>) for a readable workflow, and limit my data to only what was necessary for plotting and in relation to data being presented, using filter() and select(). I also tried to customize plots in ggplot2 and by taking into consideration communication through graphs and visualizations, such as customizing the color palette, and background, or using on of their new themes with ggplot2. Overall, I was not only trying to complete the work, but push my own development as a problem solver.

## Peer Support and Collaboration 

I grew tremendously. I started being far below sub par- one or two words at most, and have grown to have clear concise notes. I still have room to grow, as I believe that I should instead have added more context. I think that what I have written in my last couple reviews has been good, but I think I should add more context as everything I said is legitimate but would do better with some explanation and examples. I thoroughly read through the code when I was given it to review, and made a significant effort to give them good advice.

Lab 4 peer Review

![](images/Screenshot 2025-10-26 at 8.44.42 PM.png)
